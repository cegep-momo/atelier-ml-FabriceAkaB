{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bced6345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Charger l'architecture\n",
    "with open(\"modele/modele.json\", \"r\") as f:\n",
    "    modele_json = f.read()\n",
    "modele = model_from_json(modele_json)\n",
    "\n",
    "# Charger les poids\n",
    "modele.load_weights(\"modele/modele.weights.h5\")\n",
    "print(\"Modèle chargé.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048b6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "LONGUEUR_IMAGE = 28\n",
    "LARGEUR_IMAGE = 28\n",
    "\n",
    "observations_test = pd.read_csv('datas/fashion-mnist_test.csv')\n",
    "X_test = np.array(observations_test.iloc[:, 1:])\n",
    "y_test = np.array(observations_test.iloc[:, 0])\n",
    "\n",
    "def prep(x):\n",
    "    x = x.reshape(x.shape[0], LARGEUR_IMAGE, LONGUEUR_IMAGE, 1).astype('float32')\n",
    "    x /= 255.0\n",
    "    return x\n",
    "\n",
    "X_test_img = prep(X_test)\n",
    "\n",
    "classes = [\"Un T-shirt/haut\",\"Un pantalon\",\"Un pull\",\"Une robe\",\"Un manteau\",\n",
    "           \"Des sandales\",\"Une chemise\",\"Des baskets\",\"Un sac\",\"Des bottes de cheville\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db8c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x74e7d427b880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Image 0 -> prédiction: Un T-shirt/haut (label réel: 0)\n",
      "Image 1 -> prédiction: Un pantalon (label réel: 1)\n",
      "Image 2 -> prédiction: Une chemise (label réel: 2)\n"
     ]
    }
   ],
   "source": [
    "idx = [0, 1, 2]   # 3 exemples\n",
    "probas = modele.predict(X_test_img[idx])\n",
    "preds = np.argmax(probas, axis=1)\n",
    "\n",
    "for i, p in zip(idx, preds):\n",
    "    print(f\"Image {i} -> prédiction: {classes[p]} (label réel: {y_test[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abaca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Selon moi l'image est : Un pantalon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=28, content_size=20):\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # redimensionne sans déformer\n",
    "    w, h = image.size\n",
    "    if w > h:\n",
    "        new_w, new_h = content_size, max(1, round(content_size * h / w))\n",
    "    else:\n",
    "        new_h, new_w = content_size, max(1, round(content_size * w / h))\n",
    "    resized = image.resize((new_w, new_h), Image.LANCZOS).filter(ImageFilter.SHARPEN)\n",
    "    # centre sur un canevas blanc 28x28\n",
    "    canvas = Image.new('L', (target_size, target_size), 255)\n",
    "    x_off = (target_size - new_w)//2\n",
    "    y_off = (target_size - new_h)//2\n",
    "    canvas.paste(resized, (x_off, y_off))\n",
    "    # inverse fond blanc -> noir et normalise\n",
    "    arr = (255 - np.array(canvas).astype('float32'))/255.0\n",
    "    return arr.reshape(1, target_size, target_size, 1)\n",
    "\n",
    "images_dir = \"images\"\n",
    "supported_ext = (\".png\", \".jpg\", \".jpeg\", \".bmp\")\n",
    "\n",
    "for filename in sorted(os.listdir(images_dir)):\n",
    "    if not filename.lower().endswith(supported_ext):\n",
    "        continue\n",
    "    img_path = os.path.join(images_dir, filename)\n",
    "    img = load_and_preprocess_image(img_path)\n",
    "    proba = modele.predict(img)[0]\n",
    "    pred = np.argmax(proba)\n",
    "    print(f\"Selon moi l'image {filename} est : {classes[pred]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
